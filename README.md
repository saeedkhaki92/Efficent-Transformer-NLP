# Efficent-Transformer-NLP
The goal of this project is to use the Reformer, also known as the efficient Transformer, to generate a dialogues.

In this project, I use the Reformer, also known as the efficient Transformer, to generate a dialogue between two bots. I will feed conversations to your model and it will learn how to understand the context of each one. Not only will it learn how to answer questions but it will also know how to ask questions if it needs more info. For example, after a customer asks for a train ticket, the chatbot can ask what time the said customer wants to leave.




![Alt Text](https://github.com/saeedkhaki92/NLP-Question-duplicates/blob/main/meme.png)


## Getting Started

### Dependencies

Following packages should be installed on python 3:

- Trax
- numpy
- random

<a href="https://github.com/google/trax" target="_blank">Trax</a> is an end-to-end library for deep learning that focuses on clear code and speed. It is actively used and maintained in the Google Brain team. It is faster than Tensorflow and Pytorch and also the codes are more clear. It also supprts both TPUs and GPUs.




## Dataset

I used the MultiWoz dataset. It has more than 10,000 human annotated dialogues and spans multiple domains and topics. Some dialogues include multiple domains and others include single domains.
